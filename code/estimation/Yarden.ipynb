{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:00.885291Z",
     "start_time": "2024-10-18T16:47:00.883429Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:00.901102Z",
     "start_time": "2024-10-18T16:47:00.889218Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = '/Users/gurkeinan/semester6/Causal-Inference/Project/code/data/processed_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:00.956166Z",
     "start_time": "2024-10-18T16:47:00.948263Z"
    }
   },
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "\n",
    "t = data['Adult']\n",
    "y = data['Target']\n",
    "X = data.drop(columns=['Adult', 'Target'])\n",
    "\n",
    "numerical_columns = ['Previous qualification (grade)', 'Admission grade', 'Unemployment rate', 'Inflation rate', 'GDP']\n",
    "categorical_columns = list(set(X.columns) - set(numerical_columns))\n",
    "\n",
    "# Scaling numerical columns\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Combine features and treatment variable\n",
    "X_full = pd.concat([X, t], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:00.986119Z",
     "start_time": "2024-10-18T16:47:00.984469Z"
    }
   },
   "outputs": [],
   "source": [
    "method_results = {}\n",
    "method_CIs = {}\n",
    "method_bootstrap_values = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve for $Y \\mid X, t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:04.179916Z",
     "start_time": "2024-10-18T16:47:01.022273Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a Random Forest Classifier model to predict the target variable\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Fit a Logistic Regression model to predict the target variable\n",
    "model_lr = LogisticRegression(random_state=42)\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Fit a Gradient Boosting Classifier model to predict the target variable\n",
    "model_gb = GradientBoostingClassifier(random_state=42)\n",
    "model_gb.fit(X_train, y_train)\n",
    "\n",
    "# Fit an SVM model to predict the target variable\n",
    "model_svm = SVC(probability=True, random_state=42)\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions for test data\n",
    "y_pred_rf = model_rf.predict_proba(X_test)[:, 1]\n",
    "y_pred_lr = model_lr.predict_proba(X_test)[:, 1]\n",
    "y_pred_gb = model_gb.predict_proba(X_test)[:, 1]\n",
    "y_pred_svm = model_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve for Random Forest\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate the ROC curve for Logistic Regression\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "\n",
    "# Calculate the ROC curve for Gradient Boosting\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, y_pred_gb)\n",
    "\n",
    "# Calculate the ROC curve for SVM\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot(fpr_gb, tpr_gb, label=f'Gradient Boosting (AUC = {roc_auc_gb:.2f})')\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {roc_auc_svm:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that Random Forest, Gradient Boosting and SVM have the highest AUC. Therefore, we choose Random Forest to predict the target variable given the feature set and the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve $T \\mid X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:06.451145Z",
     "start_time": "2024-10-18T16:47:04.215505Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, t, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a Random Forest Classifier model to predict the treatment variable\n",
    "model_rf_t = RandomForestClassifier(random_state=42)\n",
    "model_rf_t.fit(X_train, y_train)\n",
    "\n",
    "# Fit a Logistic Regression model to predict the treatment variable\n",
    "model_lr_t = LogisticRegression(random_state=42)\n",
    "model_lr_t.fit(X_train, y_train)\n",
    "\n",
    "# Fit a Gradient Boosting Classifier model to predict the treatment variable\n",
    "model_gb_t = GradientBoostingClassifier(random_state=42)\n",
    "model_gb_t.fit(X_train, y_train)\n",
    "\n",
    "# Fit an SVM model to predict the treatment variable\n",
    "model_svm_t = SVC(probability=True, random_state=42)\n",
    "model_svm_t.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for test data\n",
    "y_pred_rf_t = model_rf_t.predict_proba(X_test)[:, 1]\n",
    "y_pred_lr_t = model_lr_t.predict_proba(X_test)[:, 1]\n",
    "y_pred_gb_t = model_gb_t.predict_proba(X_test)[:, 1]\n",
    "y_pred_svm_t = model_svm_t.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve for Random Forest\n",
    "fpr_rf_t, tpr_rf_t, _ = roc_curve(y_test, y_pred_rf_t)\n",
    "roc_auc_rf_t = roc_auc_score(y_test, y_pred_rf_t)\n",
    "\n",
    "# Calculate the ROC curve for Logistic Regression\n",
    "fpr_lr_t, tpr_lr_t, _ = roc_curve(y_test, y_pred_lr_t)\n",
    "roc_auc_lr_t = roc_auc_score(y_test, y_pred_lr_t)\n",
    "\n",
    "# Calculate the ROC curve for Gradient Boosting\n",
    "fpr_gb_t, tpr_gb_t, _ = roc_curve(y_test, y_pred_gb_t)\n",
    "roc_auc_gb_t = roc_auc_score(y_test, y_pred_gb_t)\n",
    "\n",
    "# Calculate the ROC curve for SVM\n",
    "fpr_svm_t, tpr_svm_t, _ = roc_curve(y_test, y_pred_svm_t)\n",
    "roc_auc_svm_t = roc_auc_score(y_test, y_pred_svm_t)\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_rf_t, tpr_rf_t, label=f'Random Forest (AUC = {roc_auc_rf_t:.2f})')\n",
    "plt.plot(fpr_lr_t, tpr_lr_t, label=f'Logistic Regression (AUC = {roc_auc_lr_t:.2f})')\n",
    "plt.plot(fpr_gb_t, tpr_gb_t, label=f'Gradient Boosting (AUC = {roc_auc_gb_t:.2f})')\n",
    "plt.plot(fpr_svm_t, tpr_svm_t, label=f'SVM (AUC = {roc_auc_svm_t:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that Random Forest, Gradient Boosting and SVM have the highest AUC. Therefore, we choose Random Forest to predict the target variable given the feature set and the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariate Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:06.798437Z",
     "start_time": "2024-10-18T16:47:06.490841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a Random Forest Classifier model to predict the target variable\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_full, y)\n",
    "\n",
    "# Make predictions for all data points\n",
    "y_pred_all = model.predict(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:47:06.901543Z",
     "start_time": "2024-10-18T16:47:06.831772Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_measures_s_learner(X, y_pred_model):\n",
    "    # Predict outcomes for all individuals under treatment condition\n",
    "    X_treated = X.copy()\n",
    "    X_treated['Adult'] = 1\n",
    "    y_pred_treated = y_pred_model.predict_proba(X_treated)[:, 1]\n",
    "\n",
    "    # Predict outcomes for all individuals under control condition\n",
    "    X_control = X.copy()\n",
    "    X_control['Adult'] = 0\n",
    "    y_pred_control = y_pred_model.predict_proba(X_control)[:, 1]\n",
    "\n",
    "    # Calculate individual treatment effects\n",
    "    individual_effects = y_pred_treated - y_pred_control\n",
    "\n",
    "    # Calculate ATE\n",
    "    ATE = np.mean(individual_effects)\n",
    "\n",
    "    # Calculate ATT\n",
    "    ATT = np.mean(individual_effects[X['Adult'] == 1])\n",
    "\n",
    "    # Calculate ATC\n",
    "    ATC = np.mean(individual_effects[X['Adult'] == 0])\n",
    "\n",
    "    return ATE, ATT, ATC\n",
    "\n",
    "ATE, ATT, ATC = calculate_measures_s_learner(X_full, model)\n",
    "print(f'ATE: {ATE:.4f}, ATT: {ATT:.4f}, ATC: {ATC:.4f}')\n",
    "method_results['S-learner'] = {'ATE': ATE, 'ATT': ATT, 'ATC': ATC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:12.265056Z",
     "start_time": "2024-10-18T16:47:06.935091Z"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_intervals_s_learner(X, t, y, model, num_bootstrap=1000, ci_level=95):\n",
    "    bootstrap_ATE = []\n",
    "    bootstrap_ATT = []\n",
    "    bootstrap_ATC = []\n",
    "\n",
    "    # Combine X, t, and y into a single dataframe for easier resampling\n",
    "    data = pd.concat([X, pd.Series(t, name='Adult'), pd.Series(y, name='Target')], axis=1)\n",
    "\n",
    "    # Perform bootstrap sampling\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample (resample with replacement)\n",
    "        bootstrap_sample = data.sample(n=len(data), replace=True)\n",
    "\n",
    "        # Split the bootstrap sample back into X, t, and y\n",
    "        X_bootstrap = bootstrap_sample.drop(['Adult', 'Target'], axis=1)\n",
    "        t_bootstrap = bootstrap_sample['Adult']\n",
    "        y_bootstrap = bootstrap_sample['Target']\n",
    "\n",
    "        # Refit the model on the bootstrap sample\n",
    "        bootstrap_model = clone(model)  # Create a fresh copy of the model\n",
    "        bootstrap_model.fit(pd.concat([X_bootstrap, t_bootstrap], axis=1), y_bootstrap)\n",
    "\n",
    "        # Compute the ATE, ATT, and ATC for this bootstrap sample\n",
    "        ATE, ATT, ATC = calculate_measures_s_learner(pd.concat([X_bootstrap, t_bootstrap], axis=1), bootstrap_model)\n",
    "\n",
    "        # Store the results\n",
    "        bootstrap_ATE.append(ATE)\n",
    "        bootstrap_ATT.append(ATT)\n",
    "        bootstrap_ATC.append(ATC)\n",
    "\n",
    "    # Calculate percentiles for confidence intervals\n",
    "    lower_percentile = (100 - ci_level) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "\n",
    "    ATE_CI = np.percentile(bootstrap_ATE, [lower_percentile, upper_percentile])\n",
    "    ATT_CI = np.percentile(bootstrap_ATT, [lower_percentile, upper_percentile])\n",
    "    ATC_CI = np.percentile(bootstrap_ATC, [lower_percentile, upper_percentile])\n",
    "\n",
    "    return ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC\n",
    "\n",
    "# Usage\n",
    "from sklearn.base import clone\n",
    "\n",
    "ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC = bootstrap_confidence_intervals_s_learner(X, t, y, model)\n",
    "print(f'ATE 95% CI: {ATE_CI}, ATT 95% CI: {ATT_CI}, ATC 95% CI: {ATC_CI}')\n",
    "method_CIs['S-learner'] = {'ATE_CI': ATE_CI, 'ATT_CI': ATT_CI, 'ATC_CI': ATC_CI}\n",
    "method_bootstrap_values['S-learner'] = {'ATE': bootstrap_ATE, 'ATT': bootstrap_ATT, 'ATC': bootstrap_ATC}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:12.643970Z",
     "start_time": "2024-10-18T16:52:12.304934Z"
    }
   },
   "outputs": [],
   "source": [
    "X_1 = X[X_full['Adult'] == 1]\n",
    "X_0 = X[X_full['Adult'] == 0]\n",
    "\n",
    "y_1 = data[data['Adult'] == 1]['Target']\n",
    "y_0 = data[data['Adult'] == 0]['Target']\n",
    "\n",
    "# Fit a Random Forest Classifier model to predict the target variable for each subgroup\n",
    "model_1 = RandomForestClassifier(random_state=42)\n",
    "model_1.fit(X_1, y_1)\n",
    "\n",
    "model_0 = RandomForestClassifier(random_state=42)\n",
    "model_0.fit(X_0, y_0)\n",
    "\n",
    "y_pred_all_1 = model_1.predict(X)\n",
    "y_pred_all_0 = model_0.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:12.680808Z",
     "start_time": "2024-10-18T16:52:12.677267Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_measures_t_learner(data, y_pred_all_1, y_pred_all_0):\n",
    "    treated_predictions_sum = sum(y_pred_all_1)\n",
    "    control_predictions_sum = sum(y_pred_all_0)\n",
    "\n",
    "    ATE = (treated_predictions_sum - control_predictions_sum) / n\n",
    "    ATT = (sum(y_pred_all_1[data['Adult'] == 1]) -  sum(y_pred_all_0[data['Adult'] == 1])) / sum(t)\n",
    "    ATC = (sum(y_pred_all_1[data['Adult'] == 0]) -  sum(y_pred_all_0[data['Adult'] == 0])) / (n - sum(t))\n",
    "\n",
    "    return ATE, ATT, ATC\n",
    "\n",
    "ATE, ATT, ATC = calculate_measures_t_learner(data, y_pred_all_1, y_pred_all_0)\n",
    "print(f'ATE: {ATE}, ATT: {ATT}, ATC: {ATC}')\n",
    "method_results['T-learner'] = {'ATE': ATE, 'ATT': ATT, 'ATC': ATC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:13.886145Z",
     "start_time": "2024-10-18T16:52:12.716195Z"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_intervals_t_learner(data, y_pred_all_1, y_pred_all_0, num_bootstrap=1000, ci_level=95):\n",
    "    bootstrap_ATE = []\n",
    "    bootstrap_ATT = []\n",
    "    bootstrap_ATC = []\n",
    "\n",
    "    # Perform bootstrap sampling\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample (resample with replacement)\n",
    "        bootstrap_sample = data.sample(n=len(data), replace=True)\n",
    "\n",
    "        # Get predictions for the bootstrap sample\n",
    "        y_pred_bootstrap_1 = y_pred_all_1[bootstrap_sample.index]\n",
    "        y_pred_bootstrap_0 = y_pred_all_0[bootstrap_sample.index]\n",
    "\n",
    "        # Compute the ATE, ATT, and ATC for this bootstrap sample\n",
    "        ATE, ATT, ATC = calculate_measures_t_learner(bootstrap_sample, y_pred_bootstrap_1, y_pred_bootstrap_0)\n",
    "\n",
    "        # Store the results\n",
    "        bootstrap_ATE.append(ATE)\n",
    "        bootstrap_ATT.append(ATT)\n",
    "        bootstrap_ATC.append(ATC)\n",
    "\n",
    "    # Calculate percentiles for confidence intervals\n",
    "    lower_percentile = (100 - ci_level) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "\n",
    "    ATE_CI = np.percentile(bootstrap_ATE, [lower_percentile, upper_percentile])\n",
    "    ATT_CI = np.percentile(bootstrap_ATT, [lower_percentile, upper_percentile])\n",
    "    ATC_CI = np.percentile(bootstrap_ATC, [lower_percentile, upper_percentile])\n",
    "\n",
    "    return ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC\n",
    "\n",
    "ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC = bootstrap_confidence_intervals_t_learner(data, y_pred_all_1, y_pred_all_0)\n",
    "print(f'ATE 95% CI: {ATE_CI}, ATT 95% CI: {ATT_CI}, ATC 95% CI: {ATC_CI}')\n",
    "method_CIs['T-learner'] = {'ATE_CI': ATE_CI, 'ATT_CI': ATT_CI, 'ATC_CI': ATC_CI}\n",
    "method_bootstrap_values['T-learner'] = {'ATE': bootstrap_ATE, 'ATT': bootstrap_ATT, 'ATC': bootstrap_ATC}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:14.186087Z",
     "start_time": "2024-10-18T16:52:13.920753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a Random Forest Classifier model to predict the treatment variable\n",
    "propensity_model = RandomForestClassifier(random_state=42)\n",
    "propensity_model.fit(X, t)\n",
    "\n",
    "# Calculate the propensity scores (predicted probabilities of receiving the treatment)\n",
    "e = propensity_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Clip propensity scores to avoid division by zero or extreme values (set lower and upper bounds)\n",
    "epsilon = 1e-5  # Small value to avoid dividing by 0\n",
    "e = np.clip(e, epsilon, 1 - epsilon)\n",
    "\n",
    "# Add the propensity scores to the original data\n",
    "data['propensity_score'] = e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid division by zero, we clip the propensity scores between $[\\varepsilon, 1 - \\varepsilon]$ for $\\varepsilon = 10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:14.226337Z",
     "start_time": "2024-10-18T16:52:14.221703Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_measures_IPW(y, t, e):\n",
    "    ATE = sum(y * t / e) / n - sum(y * (1 - t) / (1 - e)) / n\n",
    "    ATT = sum(y * t) / sum(t) - sum(y * (1 - t) * e / (1 - e)) / sum((1 - t) * e / (1 - e))\n",
    "    ATC = sum(y * t * (1 - e) / e) / sum(t * (1 - e) / e) - sum(y * (1 - t)) / sum(1 - t)\n",
    "\n",
    "    return ATE, ATT, ATC\n",
    "\n",
    "ATE, ATT, ATC = calculate_measures_IPW(y, t, e)\n",
    "print(f'ATE: {ATE}, ATT: {ATT}, ATC: {ATC}')\n",
    "method_results['IPW'] = {'ATE': ATE, 'ATT': ATT, 'ATC': ATC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:16.137087Z",
     "start_time": "2024-10-18T16:52:14.263307Z"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_intervals_IPW(data, num_bootstrap=1000, ci_level=95):\n",
    "    bootstrap_ATE = []\n",
    "    bootstrap_ATT = []\n",
    "    bootstrap_ATC = []\n",
    "\n",
    "    # Perform bootstrap sampling\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample (resample with replacement)\n",
    "        bootstrap_sample = data.sample(n=len(data), replace=True)\n",
    "\n",
    "        # Get the outcomes, treatment assignments, and propensity scores for the bootstrap sample\n",
    "        y_bootstrap = bootstrap_sample['Target']\n",
    "        t_bootstrap = bootstrap_sample['Adult']\n",
    "        e_bootstrap = bootstrap_sample['propensity_score']\n",
    "\n",
    "        # Compute the ATE, ATT, and ATC for this bootstrap sample\n",
    "        ATE, ATT, ATC = calculate_measures_IPW(y_bootstrap, t_bootstrap, e_bootstrap)\n",
    "\n",
    "        # Store the results\n",
    "        bootstrap_ATE.append(ATE)\n",
    "        bootstrap_ATT.append(ATT)\n",
    "        bootstrap_ATC.append(ATC)\n",
    "\n",
    "    # Calculate percentiles for confidence intervals\n",
    "    lower_percentile = (100 - ci_level) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "\n",
    "    ATE_CI = np.percentile(bootstrap_ATE, [lower_percentile, upper_percentile])\n",
    "    ATT_CI = np.percentile(bootstrap_ATT, [lower_percentile, upper_percentile])\n",
    "    ATC_CI = np.percentile(bootstrap_ATC, [lower_percentile, upper_percentile])\n",
    "\n",
    "    return ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC\n",
    "\n",
    "ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC = bootstrap_confidence_intervals_IPW(data)\n",
    "print(f'ATE 95% CI: {ATE_CI}, ATT 95% CI: {ATT_CI}, ATC 95% CI: {ATC_CI}')\n",
    "method_CIs['IPW'] = {'ATE_CI': ATE_CI, 'ATT_CI': ATT_CI, 'ATC_CI': ATC_CI}\n",
    "method_bootstrap_values['IPW'] = {'ATE': bootstrap_ATE, 'ATT': bootstrap_ATT, 'ATC': bootstrap_ATC}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Score Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:16.177730Z",
     "start_time": "2024-10-18T16:52:16.170899Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_measures_propensity_score_stratification(data, num_strata=5):\n",
    "    # Create strata based on the propensity scores\n",
    "    data['strata'] = pd.qcut(data['propensity_score'], num_strata, labels=False)\n",
    "\n",
    "    # Calculate the ATE, ATT, and ATC for each stratum\n",
    "    results = []\n",
    "    for i in range(num_strata):\n",
    "        treated = data[(data['strata'] == i) & (data['Adult'] == 1)]\n",
    "        control = data[(data['strata'] == i) & (data['Adult'] == 0)]\n",
    "\n",
    "        # Calculate mean outcomes in each stratum for treated and control groups\n",
    "        treated_mean = treated['Target'].mean()\n",
    "        control_mean = control['Target'].mean()\n",
    "\n",
    "        # Calculate treatment effect within each stratum\n",
    "        strata_effect = treated_mean - control_mean\n",
    "\n",
    "        # Collect results\n",
    "        results.append({\n",
    "            'strata': i,\n",
    "            'n_treated': len(treated),\n",
    "            'n_control': len(control),\n",
    "            'n_total': len(treated) + len(control),\n",
    "            'effect': strata_effect\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for easier processing\n",
    "    strata_df = pd.DataFrame(results)\n",
    "\n",
    "    # Calculate overall ATE, ATT, and ATC\n",
    "\n",
    "    # ATE: Weighted by total individuals in each stratum\n",
    "    ATE = np.sum(strata_df['effect'] * strata_df['n_total'] / np.sum(strata_df['n_total']))\n",
    "\n",
    "    # ATT: Weighted by number of treated individuals in each stratum\n",
    "    ATT = np.sum(strata_df['effect'] * strata_df['n_treated'] / np.sum(strata_df['n_treated']))\n",
    "\n",
    "    # ATC: Weighted by number of control individuals in each stratum\n",
    "    ATC = np.sum(strata_df['effect'] * strata_df['n_control'] / np.sum(strata_df['n_control']))\n",
    "\n",
    "    return ATE, ATT, ATC\n",
    "\n",
    "ATE, ATT, ATC = calculate_measures_propensity_score_stratification(data)\n",
    "print(f'ATE: {ATE}, ATT: {ATT}, ATC: {ATC}')\n",
    "method_results['Propensity score stratification'] = {'ATE': ATE, 'ATT': ATT, 'ATC': ATC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:18.790650Z",
     "start_time": "2024-10-18T16:52:16.212375Z"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_intervals_propensity_score_stratification(data, num_bootstrap=1000, ci_level=95):\n",
    "    bootstrap_ATE = []\n",
    "    bootstrap_ATT = []\n",
    "    bootstrap_ATC = []\n",
    "\n",
    "    # Perform bootstrap sampling\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample (resample with replacement)\n",
    "        bootstrap_sample = data.sample(n=len(data), replace=True)\n",
    "\n",
    "        # Compute the ATE, ATT, and ATC for this bootstrap sample\n",
    "        ATE, ATT, ATC = calculate_measures_propensity_score_stratification(bootstrap_sample)\n",
    "\n",
    "        # Store the results\n",
    "        bootstrap_ATE.append(ATE)\n",
    "        bootstrap_ATT.append(ATT)\n",
    "        bootstrap_ATC.append(ATC)\n",
    "\n",
    "    # Calculate percentiles for confidence intervals\n",
    "    lower_percentile = (100 - ci_level) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "\n",
    "    ATE_CI = np.percentile(bootstrap_ATE, [lower_percentile, upper_percentile])\n",
    "    ATT_CI = np.percentile(bootstrap_ATT, [lower_percentile, upper_percentile])\n",
    "    ATC_CI = np.percentile(bootstrap_ATC, [lower_percentile, upper_percentile])\n",
    "\n",
    "    return ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC\n",
    "\n",
    "ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC = bootstrap_confidence_intervals_propensity_score_stratification(data)\n",
    "print(f'ATE 95% CI: {ATE_CI}, ATT 95% CI: {ATT_CI}, ATC 95% CI: {ATC_CI}')\n",
    "method_CIs['Propensity score stratification'] = {'ATE_CI': ATE_CI, 'ATT_CI': ATT_CI, 'ATC_CI': ATC_CI}\n",
    "method_bootstrap_values['Propensity score stratification'] = {'ATE': bootstrap_ATE, 'ATT': bootstrap_ATT, 'ATC': bootstrap_ATC}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly Robust Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:19.165799Z",
     "start_time": "2024-10-18T16:52:18.824623Z"
    }
   },
   "outputs": [],
   "source": [
    "X_1 = X[X_full['Adult'] == 1]\n",
    "X_0 = X[X_full['Adult'] == 0]\n",
    "\n",
    "y_1 = data[data['Adult'] == 1]['Target']\n",
    "y_0 = data[data['Adult'] == 0]['Target']\n",
    "\n",
    "# Fit a Random Forest Classifier model to predict the target variable for each subgroup\n",
    "model_1 = RandomForestClassifier(random_state=42)\n",
    "model_1.fit(X_1, y_1)\n",
    "\n",
    "model_0 = RandomForestClassifier(random_state=42)\n",
    "model_0.fit(X_0, y_0)\n",
    "\n",
    "y_pred_all_1 = model_1.predict(X)\n",
    "y_pred_all_0 = model_0.predict(X)\n",
    "\n",
    "g_1_score = y_pred_all_1 + (t / e) * (y - y_pred_all_1)\n",
    "g_0_score = y_pred_all_0 + ((1 - t) / (1 - e)) * (y - y_pred_all_0)\n",
    "\n",
    "data['g_1_score'] = g_1_score\n",
    "data['g_0_score'] = g_0_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:19.204884Z",
     "start_time": "2024-10-18T16:52:19.201338Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_measures_doubly_robust(data, y_pred_all_1, y_pred_all_0, y, t, e):\n",
    "    ATE = sum(data['g_1_score']) / n - sum(data['g_0_score']) / n\n",
    "    ATT = sum(t * y - ((t - e) * y_pred_all_0 / (1 - e))) / sum(t)\n",
    "    ATC = sum((1 - e) * t * y / e - ((t - e) * y_pred_all_1 / e) - ((1 - t) * y)) / sum(1 - t)\n",
    "\n",
    "    return ATE, ATT, ATC\n",
    "\n",
    "ATE, ATT, ATC = calculate_measures_doubly_robust(data, y_pred_all_1, y_pred_all_0, y, t, e)\n",
    "print(f'ATE: {ATE}, ATT: {ATT}, ATC: {ATC}')\n",
    "method_results['Doubly robust'] = {'ATE': ATE, 'ATT': ATT, 'ATC': ATC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:20.554158Z",
     "start_time": "2024-10-18T16:52:19.240484Z"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_intervals_doubly_robust(data, y_pred_all_1, y_pred_all_0, num_bootstrap=1000, ci_level=95):\n",
    "    bootstrap_ATE = []\n",
    "    bootstrap_ATT = []\n",
    "    bootstrap_ATC = []\n",
    "\n",
    "    # Perform bootstrap sampling\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample (resample with replacement)\n",
    "        bootstrap_sample = data.sample(n=len(data), replace=True)\n",
    "\n",
    "        # Get the outcomes, treatment assignments, and propensity scores for the bootstrap sample\n",
    "        y_bootstrap = bootstrap_sample['Target']\n",
    "        t_bootstrap = bootstrap_sample['Adult']\n",
    "        e_bootstrap = bootstrap_sample['propensity_score']\n",
    "        y_pred_all_1_bootstrap = y_pred_all_1[bootstrap_sample.index]\n",
    "        y_pred_all_0_bootstrap = y_pred_all_0[bootstrap_sample.index]\n",
    "\n",
    "        # Compute the ATE, ATT, and ATC for this bootstrap sample\n",
    "        ATE, ATT, ATC = calculate_measures_doubly_robust(bootstrap_sample, y_pred_all_1_bootstrap, y_pred_all_0_bootstrap, y_bootstrap, t_bootstrap, e_bootstrap)\n",
    "\n",
    "        # Store the results\n",
    "        bootstrap_ATE.append(ATE)\n",
    "        bootstrap_ATT.append(ATT)\n",
    "        bootstrap_ATC.append(ATC)\n",
    "\n",
    "    # Calculate percentiles for confidence intervals\n",
    "    lower_percentile = (100 - ci_level) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "\n",
    "    ATE_CI = np.percentile(bootstrap_ATE, [lower_percentile, upper_percentile])\n",
    "    ATT_CI = np.percentile(bootstrap_ATT, [lower_percentile, upper_percentile])\n",
    "    ATC_CI = np.percentile(bootstrap_ATC, [lower_percentile, upper_percentile])\n",
    "\n",
    "    return ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC\n",
    "\n",
    "ATE_CI, ATT_CI, ATC_CI, bootstrap_ATE, bootstrap_ATT, bootstrap_ATC = bootstrap_confidence_intervals_doubly_robust(data, y_pred_all_1, y_pred_all_0)\n",
    "print(f'ATE 95% CI: {ATE_CI}, ATT 95% CI: {ATT_CI}, ATC 95% CI: {ATC_CI}')\n",
    "method_CIs['Doubly robust'] = {'ATE_CI': ATE_CI, 'ATT_CI': ATT_CI, 'ATC_CI': ATC_CI}\n",
    "method_bootstrap_values['Doubly robust'] = {'ATE': bootstrap_ATE, 'ATT': bootstrap_ATT, 'ATC': bootstrap_ATC}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:20.821317Z",
     "start_time": "2024-10-18T16:52:20.627080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the ATE, ATT, and ATC estimates for each method\n",
    "ATE_values = [method_bootstrap_values[method]['ATE'] for method in method_bootstrap_values]\n",
    "ATT_values = [method_bootstrap_values[method]['ATT'] for method in method_bootstrap_values]\n",
    "ATC_values = [method_bootstrap_values[method]['ATC'] for method in method_bootstrap_values]\n",
    "\n",
    "ATE_CIs = [method_CIs[method]['ATE_CI'] for method in method_CIs]\n",
    "ATT_CIs = [method_CIs[method]['ATT_CI'] for method in method_CIs]\n",
    "ATC_CIs = [method_CIs[method]['ATC_CI'] for method in method_CIs]\n",
    "\n",
    "colors = ['lightblue', 'lightgreen', 'lightpink', 'lightgrey', 'lightyellow']\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "boxes_ate = plt.boxplot(ATE_values, patch_artist=True, labels=list(method_bootstrap_values.keys()))\n",
    "for patch, color in zip(boxes_ate['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "plt.title('ATE Estimates')\n",
    "plt.ylabel('ATE')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "boxes_att = plt.boxplot(ATT_values, patch_artist=True, labels=list(method_bootstrap_values.keys()))\n",
    "for patch, color in zip(boxes_att['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "plt.title('ATT Estimates')\n",
    "plt.ylabel('ATT')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "boxes_atc = plt.boxplot(ATC_values, patch_artist=True, labels=list(method_bootstrap_values.keys()))\n",
    "for patch, color in zip(boxes_atc['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "plt.title('ATC Estimates')\n",
    "plt.ylabel('ATC')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Features for $Y \\mid X, t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:21.054927Z",
     "start_time": "2024-10-18T16:52:20.827649Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a Random Forest Classifier model to predict the target variable\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "feature_scores = pd.Series(model_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:21.609454Z",
     "start_time": "2024-10-18T16:52:21.105110Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = len(feature_scores)\n",
    "palette = sns.color_palette(\"rainbow\", num_features)[::-1]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(30, 24))\n",
    "ax = sns.barplot(x=feature_scores, y=feature_scores.index, palette=palette)\n",
    "ax.set_title(\"Visualize Feature Scores of the Features\")\n",
    "ax.set_yticklabels(feature_scores.index)\n",
    "ax.set_xlabel(\"Feature Importance Score\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Features for $T \\mid X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T16:52:22.446668Z",
     "start_time": "2024-10-18T16:52:21.622529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train_t, X_test_t, t_train, t_test = train_test_split(X, t, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a Random Forest Classifier model to predict the treatment variable\n",
    "model_rf_t = RandomForestClassifier(random_state=42)\n",
    "model_rf_t.fit(X_train_t, t_train)\n",
    "\n",
    "# Calculate feature importances\n",
    "feature_scores_t = pd.Series(model_rf_t.feature_importances_, index=X_train_t.columns).sort_values(ascending=False)\n",
    "\n",
    "# Display feature importances\n",
    "print(\"Feature Importances for T | X:\")\n",
    "print(feature_scores_t)\n",
    "\n",
    "# Visualize feature importances\n",
    "num_features = len(feature_scores_t)\n",
    "palette = sns.color_palette(\"rainbow\", num_features)[::-1]\n",
    "\n",
    "plt.figure(figsize=(30, 24))\n",
    "ax = sns.barplot(x=feature_scores_t, y=feature_scores_t.index, palette=palette)\n",
    "ax.set_title(\"Feature Importance Scores for T | X\")\n",
    "ax.set_xlabel(\"Feature Importance Score\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
